# Sistema de Monitoreo de Cloud Providers - Titanocloud

Este sistema monitorea en tiempo real el estado de los principales proveedores cloud a nivel global mediante scraping de DownDetector.

## üéØ Proveedores Monitoreados

- **AWS** (Amazon Web Services)
- **Azure** (Microsoft Azure)
- **Google Cloud**
- **Oracle Cloud**
- **Huawei Cloud**
- **Alibaba Cloud**
- **OVHcloud**
- **Vultr**
- **Linode**
- **Unihost**

## üåç Regiones Monitoreadas

El sistema scrapea datos de m√∫ltiples regiones de DownDetector:
- Global (.com)
- Canad√° (.ca)
- M√©xico (.mx)
- Per√∫ (.pe)
- Colombia (.com.co)

## üìÅ Estructura de Archivos

\`\`\`
/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ cloud-status-scraper.ts    # Script de scraping
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cloud-status/          # API endpoint para status actual
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cloud-history/         # API endpoint para hist√≥rico
‚îÇ   ‚îî‚îÄ‚îÄ monitor/
‚îÇ       ‚îî‚îÄ‚îÄ page.tsx               # Dashboard visual
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ cloud-monitor-chart.tsx    # Componente de gr√°ficas
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ cloud-status.json          # Estado actual (generado)
    ‚îî‚îÄ‚îÄ cloud-history.json         # Hist√≥rico (generado)
\`\`\`

## üöÄ C√≥mo Ejecutar

### 1. Ejecutar el Scraper Manualmente

Para ejecutar el scraper una vez y generar datos de prueba:

\`\`\`bash
npx tsx scripts/cloud-status-scraper.ts
\`\`\`

Esto crear√°/actualizar√° los archivos en `data/`:
- `cloud-status.json` - Estado actual de todos los servicios
- `cloud-history.json` - Hist√≥rico de reportes por servicio

### 2. Programar el Scraper Autom√°tico

**Opci√≥n A: Usar cron en el servidor**

Edita tu crontab:
\`\`\`bash
crontab -e
\`\`\`

Agrega esta l√≠nea para ejecutar cada 5 minutos:
\`\`\`
*/5 * * * * cd /ruta/a/tu/proyecto && npx tsx scripts/cloud-status-scraper.ts >> /var/log/cloud-scraper.log 2>&1
\`\`\`

**Opci√≥n B: Usar un proceso Node.js continuo**

Crea `scripts/scheduler.ts`:
\`\`\`typescript
import { spawn } from 'child_process'

async function runScraper() {
  console.log(`[${new Date().toISOString()}] Ejecutando scraper...`)
  
  const scraper = spawn('npx', ['tsx', 'scripts/cloud-status-scraper.ts'])
  
  scraper.stdout.on('data', (data) => {
    console.log(data.toString())
  })
  
  scraper.stderr.on('data', (data) => {
    console.error(data.toString())
  })
}

// Ejecutar inmediatamente
runScraper()

// Luego cada 5 minutos
setInterval(runScraper, 5 * 60 * 1000)
\`\`\`

Ejecuta con:
\`\`\`bash
npx tsx scripts/scheduler.ts
\`\`\`

**Opci√≥n C: Usar PM2 (recomendado para producci√≥n)**

Instala PM2:
\`\`\`bash
npm install -g pm2
\`\`\`

Crea `ecosystem.config.js`:
\`\`\`javascript
module.exports = {
  apps: [{
    name: 'cloud-scraper',
    script: 'npx',
    args: 'tsx scripts/scheduler.ts',
    cron_restart: '*/5 * * * *',
    autorestart: true,
    watch: false,
    max_memory_restart: '200M',
  }]
}
\`\`\`

Inicia:
\`\`\`bash
pm2 start ecosystem.config.js
pm2 save
pm2 startup  # Para iniciar con el sistema
\`\`\`

### 3. Ver el Dashboard

Accede a la p√°gina del monitor:
\`\`\`
http://localhost:3000/monitor
\`\`\`

O en producci√≥n:
\`\`\`
https://tu-dominio.com/monitor
\`\`\`

## üìä Caracter√≠sticas del Dashboard

- **Gr√°ficas en tiempo real** con Chart.js mostrando tendencias por regi√≥n
- **Logos reales** de cada proveedor usando Clearbit Logo API
- **Estados colorizados**:
  - üü¢ Verde: Operacional (< 100 reportes)
  - üü° Amarillo: Degradado (100-299 reportes)
  - üî¥ Rojo: Ca√≠do (‚â• 300 reportes)
- **Vista por regi√≥n** para cada proveedor
- **Actualizaci√≥n autom√°tica** cada 60 segundos sin recargar

## üîß Configuraci√≥n Avanzada

### Cambiar Frecuencia de Scraping

Edita `scripts/cloud-status-scraper.ts` y ajusta el delay entre requests:
\`\`\`typescript
await new Promise((resolve) => setTimeout(resolve, 1000)) // 1 segundo entre servicios
\`\`\`

### Cambiar Hist√≥rico Guardado

Por defecto guarda 288 puntos (24 horas si se ejecuta cada 5 min). Para cambiar:

En `cloud-status-scraper.ts`:
\`\`\`typescript
if (history[key].length > 288) {  // Cambia este n√∫mero
  history[key] = history[key].slice(-288)
}
\`\`\`

### A√±adir M√°s Proveedores

Edita el array `CLOUD_PROVIDERS` en `scripts/cloud-status-scraper.ts`:
\`\`\`typescript
const CLOUD_PROVIDERS = [
  // ... existentes ...
  { slug: "nuevo-servicio", name: "Nuevo Servicio", clearbit: "dominio.com" },
]
\`\`\`

**Nota:** Verifica que el slug coincida con la URL de DownDetector.

## üõ†Ô∏è Troubleshooting

### El scraper no genera datos

1. Verifica que el directorio `data/` existe
2. Revisa los logs para errores de red
3. Aseg√∫rate de tener conexi√≥n a internet
4. Verifica que DownDetector no est√° bloqueando tu IP

### Las gr√°ficas no se muestran

1. Verifica que `cloud-history.json` tiene datos
2. Abre la consola del navegador para ver errores
3. Aseg√∫rate de que Chart.js est√° correctamente instalado:
   \`\`\`bash
   npm install chart.js react-chartjs-2
   \`\`\`

### Los logos no cargan

Los logos usan Clearbit Logo API. Si alguno falla:
1. Verifica la URL del dominio en el array `CLOUD_PROVIDERS`
2. Algunos servicios pueden no tener logo en Clearbit
3. Considera descargar logos localmente a `public/logos/`

## üìù Notas Legales

- Este sistema scrapea datos de DownDetector para uso informativo
- Respeta `robots.txt` y no hagas requests excesivos
- Para uso comercial, considera contactar a DownDetector para acceso oficial a su API
- Los datos son estimaciones basadas en reportes de usuarios, no estados oficiales

## üîí Seguridad

- No expone credenciales (no se requieren)
- Rate limiting incorporado (1s entre requests)
- Maneja errores de red gracefully
- Los datos se almacenan localmente

## üìà Pr√≥ximas Mejoras

- [ ] Integraci√≥n con Andrea IA para an√°lisis autom√°tico
- [ ] Alertas por Webhook/Email cuando un servicio cae
- [ ] Exportar reportes PDF
- [ ] Comparativas hist√≥ricas por semana/mes
- [ ] API p√∫blica para consultar datos
- [ ] Dashboard admin para configuraci√≥n
